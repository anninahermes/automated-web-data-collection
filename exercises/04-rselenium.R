# Exercise 4: RSelenium
# Goal: Use RSelenium to automate a browser, interact with a page, and extract content after JS loads.


# Install chromdriver (Chrome) or geckodriver (Firefox)
# https://github.com/ropensci/RSelenium/issues/100

# 1. Load the RSelenium package


# 2. Start Selenium server and browser


# 3. Navigate to Google


# 4. Find the search box (by name attribute 'q')


# 5. Enter your search term (e.g., "web scraping in R")


# 6. Wait for results to load (optional: Sys.sleep(2) or use explicit waits)


# 7. Extract the titles of the search results (as an example)


# 8. Close browser and stop server


# ---
# Try to:
# - Find other dynamic websites to scrape
# - Interact with different elements (links, forms, etc.)
# - Extract and print specific content from the loaded page 